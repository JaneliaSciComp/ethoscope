#@include 
NULL
#' Read data from aresult file.
#' 
#' This function is used to convert all the information
#' contained in a result file generated by PSV into R dataframe(s).
#'
#' @param FILE the name of the input file.
#' @param rois a vector of ROI indices to read. NULL returns all ROIs
#' @param min_time exclude data before min_time (in seconds)
#' @param max_time exclude data after max_time (in seconds)
#' @param condition_df an optionnal dataframe to provide experiemental conditions for each ROI. This dataframe should have one row per ROI and, at least, a \code{roi_id} column.
#' @param relative_distance whether distance is converted between 0 and 1 relatively to the width of the ROI. If FALSE, varibales such as x,y, w and h are returned is returned in absolute number of pixels.
#' @param time_in_seconds whether time is expressed in seconds (TRUE) or milliseconds (FALSE).
#' @param reference_hour the hour, in the day, to use as t0 reference.
#' @param add_file_name whether to add the name of the input file as an extra column.
#' @param FUN an optionnal function to be applied to the resulting dataframe. It can be used, for instance, to compute summary statistics, or to transform the data.
#' @param n_core the number of core used for applying FUN to selected ROIs
#' @param ... extra arguments to be passed to \code{FUN}
#' @return If \code{rois} has only one element, a dataframe. Otherwise, a list of dataframes (one per ROI)
#' @note Analysis of many long (sevaral days) recording can use a lot of memory. 
#' Therefore, it can be advantageaous to load an process ROIs one by one.
#' @examples
#' \dontrun{
#' FILE <- "result.db"
#' out <- loadROIsFromFile(FILE,c(1,3,55))
#' #histogram of x marginal distribution
#' hist(out$ROI_1$x, nclass=100)
#' }
#' \dontrun{
#' ####### Using the FUN argument to resample data as it is loaded.
#' # This is preferable for very large dataset, or when working with
#' # little RAM.
#' # First, we compute the last time point available for all ROIs
#' out <- loadROIsFromFile(FILE, FUN=function(d)max(d$t))
#' max_t <- max(unlist(out))
#' # experiemental conditions:
#' conditions <- cbind(roi_id=1:32, expand.grid(treatment=c(T,F), genotype=LETTERS[1:4]))
#' print(conditions)
#'
#' # Then we apply the interpolateROIData to all ROIs
#'  out <- loadROIsFromFile(FILE, 
#' 	FUN=interpolateROIData, start=0,
#' 	stop = max_t, fs=1)
#' 	}
#' @seealso \code{\link{loadMetaData}} To display global informations about the experiment. 
#' @export
loadROIsFromFile <- function(FILE, rois = NULL, min_time = 0,
				max_time = Inf, relative_distances = TRUE,
				condition_df = NULL, time_in_seconds=TRUE,
				reference_hour=NULL,
				add_file_name=FALSE,
				FUN=NULL,
				n_cores=1, #fixme
			
				...){

	metadata <- loadMetaData(FILE)
	
	
	con <- dbConnect(SQLite(), FILE)
	roi_map <- as.data.table(dbGetQuery(con, "SELECT * FROM ROI_MAP"))
	var_map <- as.data.table(dbGetQuery(con, "SELECT * FROM VAR_MAP"))
	
	setkey(roi_map, roi_idx)
	setkey(var_map, var_name)
	
	available_rois  <- roi_map[ ,roi_idx]
	
	if(is.null(rois))
		rois <- available_rois
	
	matched <- rois %in% available_rois
	unmatched_idx <-  which(!matched)
	
	for(i in rois[unmatched_idx])
		warning(sprintf("Roi %i is not in the table", i))
	
	
	rois <- rois[matched]
	
	if (length(rois) == 0)
		stop(sprintf("No ROI to be read. available ROIs are: %s", str(sort(available_rois))))
	
	if(max_time == Inf)
		max_time_condition <- ""
	else
		max_time_condition <-  sprintf("AND t < %e", max_time * 1000) 
	
	min_time <- min_time * 1000 # to ms
	
	sql_query_fun <- function(i){
		print(i)
		sql_query <- sprintf("SELECT * FROM ROI_%i WHERE t >= %e %s",i,min_time, max_time_condition )
		roi_dt <- as.data.table(dbGetQuery(con, sql_query))
		roi_dt[, id := NULL]
		roi_dt[, roi_id := i]
		roi_row <- roi_map[i]
		
		
		
		if(!is.null(reference_hour)){
			p <- metadata$date_time
			hour_start <- as.numeric(format(p, "%H")) + as.numeric(format(p, "%M")) / 60 +  as.numeric(format(p, "%S")) / 3600
			ms_after_ref <- ((hour_start - reference_hour) %% 24) * 3600 * 1000
			roi_dt[, t:= (t + ms_after_ref) ]
		}
		
		if(time_in_seconds)
			roi_dt[, t:= t/1e3]
		
		roi_width <- max(c(roi_row[,w], roi_row[,h]))
		for(var_n in var_map$var_name){
			if(var_map[var_n, functional_type] == "distance"){
				roi_dt[, (var_n) := get(var_n) / roi_width]
			}
			if(var_map[var_n, sql_type] == "BOOLEAN"){
				roi_dt[, (var_n) := as.logical(get(var_n))]
			}
		}
		return(roi_dt)
	}

	out <- lapply(rois, sql_query_fun)
	dbDisconnect(con)
	
	if(!is.null(FUN)){
		
		#FIXME
		if(n_cores > 1){
			library(parallel)
			cl <- makeCluster(n_cores)
			clusterEvalQ(cl, {library(data.table); library(zoo)})
			clusterEvalQ(cl, sessionInfo())
			out <- parLapply(cl, out, FUN, ...)
			stopCluster(cl)
		}

		else{
			out <- lapply(out, FUN, ...)
		}
	}

	
	out <- rbindlist(out)
	

	if(add_file_name){
		out[, file := basename(FILE)]
		
		setkeyv(out, c("file", "roi_id"))
#~ 		print(key(out))
	}
	else{
		setkeyv(out, "roi_id")
	}
	
	
	if(!is.null(condition_df)){
		condition_df <- as.data.table(condition_df)
		out <- out[condition_df]
		}
		
	return(out)		
}

#~ dd <- loadROIsFromFile(FILE, condition_df=conditions)
NULL
#' Get metadata from a result file.
#' 
#' This function is used to obtain meta data -- such as `time and date of the experiment' , `aquisition device', `version of the software' and others--
#' contained in a result file generated by PSV.
#'
#' @param FILE the name of the input file.
#' @return A list containing fields for metadata entries
#' @examples
#' \dontrun{
#' FILE <- "result.db"
#' out <- loadMetaData(FILE)
#' names(out)
#' }
#' @seealso \code{\link{loadROIsFromFile}} to obtain raw experiemental data. 
#' @export
loadMetaData <- function(FILE){
	con <- dbConnect(SQLite(), FILE)
	metadata <- dbGetQuery(con, "SELECT * FROM METADATA")
	dbDisconnect(con)
	v <- as.list(metadata$value)
	names(v) <- metadata$field
	#fixme explicitly GMT
	v$date_time <- as.POSIXct(as.integer(v$date_time),origin="1970-01-01",tz = "GMT")
	return(v)		
	}
	

loadDAMFiles <- function(FILES, channels = NULL, min_time = 0, max_time = Inf, interval = 60){
	### hardcodded constants
	DAM_COL_TYPES <- c(
		c("integer", "character", "character", "character", "character"),
		rep("NULL", 7), ## these columns are irrelevant, NULL means we will discard them straight away
		rep("double", 32)
		)

	DAM_COL_NAMES <- c("idx", "day", "month", "year", "time",rep(NA, 7), sprintf("channel_%02d", 1:32))
	
	# todo sort files per actual dates before concat
	df_list <- lapply(FILES, function(f){
			read.table(f, colClasses = DAM_COL_TYPES, header = FALSE, col.names=DAM_COL_NAMES)
		})

	df <- do.call("rbind", df_list)
	#quick fix
	df$t <- 1:nrow(df) * interval #(s)
	df$day <- NULL
	df$month <- NULL
	df$year <- NULL
	df$time <- NULL
	
	if(is.null(channels))
		channels <- 1:32
	
	df <- subset(df, t > min_time & t < max_time)
	chans_to_fecth <- sprintf("channel_%02d", channels)
	
	df_l <- lapply(chans_to_fecth, function(x){
			data.frame(t=df$t,activity=df[,x])
		})
	names(df_l) <- chans_to_fecth	
	return(df_l)
}	

